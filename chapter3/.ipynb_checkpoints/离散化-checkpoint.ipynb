{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  amount  income             datetime    age\n",
      "0  15093    1390   10.40  2017-04-30 19:24:13   0-10\n",
      "1  15062    4024    4.68  2017-04-27 22:44:59  70-80\n",
      "2  15028    6359    3.84  2017-04-27 10:07:55  40-50\n",
      "3  15012    7759    3.70  2017-04-04 07:28:18  30-40\n",
      "4  15021     331    4.25  2017-04-08 11:14:00  70-80\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# 3.10 离散化，对连续运营数据做逻辑分层\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_table('data7.txt', names=['id', 'amount', 'income', 'datetime', 'age'])  # 读取数据文件\n",
    "print (df.head(5))  # 打印输出前5条数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  amount  income datetime    age\n",
      "0  15093    1390   10.40        6   0-10\n",
      "1  15062    4024    4.68        3  70-80\n",
      "2  15028    6359    3.84        3  40-50\n",
      "3  15012    7759    3.70        1  30-40\n",
      "4  15021     331    4.25        5  70-80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 针对时间数据的离散化\n",
    "for i, signle_data in enumerate(df['datetime']):  # 循环得到索引和对应值\n",
    "    single_data_tmp = pd.to_datetime(signle_data)  # 将时间转换为datetime格式\n",
    "    df['datetime'][i] = single_data_tmp.weekday()  # 离散化为周几\n",
    "print (df.head(5))  # 打印输出前5条数据\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  amount  income datetime  age2\n",
      "0  15093    1390   10.40        6  0-40\n",
      "1  15064    7952    4.40        0  0-40\n",
      "2  15080     503    5.72        5  0-40\n",
      "3  15068    1668    3.19        5  0-40\n",
      "4  15019    6710    3.20        0  0-40\n"
     ]
    }
   ],
   "source": [
    "# 针对多值离散数据的离散化\n",
    "map_df = pd.DataFrame([['0-10', '0-40'], ['10-20', '0-40'], ['20-30', '0-40'], ['30-40', '0-40'], ['40-50', '40-80'],\n",
    "                       ['50-60', '40-80'], ['60-70', '40-80'], ['70-80', '40-80'], ['80-90', '>80'], ['>90', '>80']],\n",
    "                      columns=['age', 'age2'])  # 定义一个要转换的新区间\n",
    "df_tmp = df.merge(map_df, left_on='age', right_on='age', how='inner')  # 数据框关联匹配\n",
    "df = df_tmp.drop('age', 1)  # 丢弃名为age的列\n",
    "print (df.head(5))  # 打印输出前5条数据\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  amount  income datetime  age2        amount1\n",
      "0  15093    1390   10.40        6  0-40   (1000, 5000]\n",
      "1  15064    7952    4.40        0  0-40  (5000, 10000]\n",
      "2  15080     503    5.72        5  0-40    (200, 1000]\n",
      "3  15068    1668    3.19        5  0-40   (1000, 5000]\n",
      "4  15019    6710    3.20        0  0-40  (5000, 10000]\n"
     ]
    }
   ],
   "source": [
    "# 针对连续数据的离散化\n",
    "# 方法1：自定义分箱区间实现离散化\n",
    "bins = [0, 200, 1000, 5000, 10000]  # 自定义区间边界\n",
    "df['amount1'] = pd.cut(df['amount'], bins)  # 使用边界做离散化\n",
    "print (df.head(5))  # 打印输出前5条数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  amount  income datetime  age2        amount1  amount2\n",
      "0  15093    1390   10.40        6  0-40   (1000, 5000]        2\n",
      "1  15064    7952    4.40        0  0-40  (5000, 10000]        1\n",
      "2  15080     503    5.72        5  0-40    (200, 1000]        2\n",
      "3  15068    1668    3.19        5  0-40   (1000, 5000]        2\n",
      "4  15019    6710    3.20        0  0-40  (5000, 10000]        1\n"
     ]
    }
   ],
   "source": [
    "# 方法2 使用聚类法实现离散化\n",
    "data = df['amount']  # 获取要聚类的数据，名为amount的列\n",
    "data_reshape = data.values.reshape((data.shape[0], 1))  # 转换数据形状\n",
    "model_kmeans = KMeans(n_clusters=4, random_state=0)  # 创建KMeans模型并指定要聚类数量\n",
    "keames_result = model_kmeans.fit_predict(data_reshape)  # 建模聚类\n",
    "df['amount2'] = keames_result  # 新离散化的数据合并到原数据框\n",
    "print (df.head(5))  # 打印输出前5条数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  income datetime  age2        amount1  amount2  amount3\n",
      "0  15093   10.40        6  0-40   (1000, 5000]        2      bad\n",
      "1  15064    4.40        0  0-40  (5000, 10000]        1  awesome\n",
      "2  15080    5.72        5  0-40    (200, 1000]        2      bad\n",
      "3  15068    3.19        5  0-40   (1000, 5000]        2      bad\n",
      "4  15019    3.20        0  0-40  (5000, 10000]        1  awesome\n"
     ]
    }
   ],
   "source": [
    "# 方法3：使用4分位数实现离散化\n",
    "df['amount3'] = pd.qcut(df['amount'], 4, labels=['bad', 'medium', 'good', 'awesome'])  # 按四分位数进行分隔\n",
    "df = df.drop('amount', 1)  # 丢弃名为amount的列\n",
    "print (df.head(5))  # 打印输出前5条数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 10.4    4.4    5.72   3.19   3.2    4.21   4.34   2.55   4.44   2.85\n   3.61   4.53   4.68   4.25   3.6    2.71   2.6    4.37   5.16   4.07\n   4.52   5.25   6.58   3.72   5.55   4.76   3.84   3.34   3.35   4.21\n   3.13   3.7    3.86   3.7    4.13   3.53   2.89   4.3    3.23   5.1\n   4.57   5.07   1.76   4.45   4.22   4.81   4.04   4.29   4.43   4.67\n   3.46   6.12   4.88   4.07   4.29   4.53   2.78   5.1    4.48   4.56\n   2.04   3.02   2.9    3.15   4.09   2.97   2.17   3.85   3.4    4.43\n   4.59   3.77   3.07   1.21   3.21   2.49   2.78   4.67   3.52   4.29\n   6.36   3.3    5.43   4.97   4.58   4.81   5.69   4.39   6.69   4.59\n   2.89   5.3    4.7    3.57   4.49   3.03   5.09   3.74   3.28   3.92].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d4405b807fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 针对连续数据的二值化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbinarizer_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 建立Binarizer模型对象\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mincome_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinarizer_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Binarizer标准化转换\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m         \"\"\"\n\u001b[0;32m-> 1802\u001b[0;31m         \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1803\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 10.4    4.4    5.72   3.19   3.2    4.21   4.34   2.55   4.44   2.85\n   3.61   4.53   4.68   4.25   3.6    2.71   2.6    4.37   5.16   4.07\n   4.52   5.25   6.58   3.72   5.55   4.76   3.84   3.34   3.35   4.21\n   3.13   3.7    3.86   3.7    4.13   3.53   2.89   4.3    3.23   5.1\n   4.57   5.07   1.76   4.45   4.22   4.81   4.04   4.29   4.43   4.67\n   3.46   6.12   4.88   4.07   4.29   4.53   2.78   5.1    4.48   4.56\n   2.04   3.02   2.9    3.15   4.09   2.97   2.17   3.85   3.4    4.43\n   4.59   3.77   3.07   1.21   3.21   2.49   2.78   4.67   3.52   4.29\n   6.36   3.3    5.43   4.97   4.58   4.81   5.69   4.39   6.69   4.59\n   2.89   5.3    4.7    3.57   4.49   3.03   5.09   3.74   3.28   3.92].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# 针对连续数据的二值化\n",
    "binarizer_scaler = preprocessing.Binarizer(threshold=df['income'].mean())  # 建立Binarizer模型对象\n",
    "income_tmp = binarizer_scaler.fit_transform(df['income'])  # Binarizer标准化转换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_tmp.resize(df['income'].shape)  # 转换数据形状\n",
    "df['income'] = income_tmp  # Binarizer标准化转换\n",
    "print (df.head(5))  # 打印输出前5条数据"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
